{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft, ifft\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "from matplotlib import style\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import datetime as dt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.signal import blackman\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.transpose(np.genfromtxt('Ham_TRAIN', delimiter=',')[:,1:])\n",
    "test_classes=np.genfromtxt('Ham_TRAIN', delimiter=',')[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesClassifier:\n",
    "    # TimeSeriesClassifier takes a data input which is an m x n numpy array where each column is a time series with m entries\n",
    "    # The reason for this Class is to avoid computing the fft 100 times during play, as well as to avoid\n",
    "    # any unnecessary computation. Roughly, it serves as an organized record of the operations you have had to do.\n",
    "    # hopefully the procedures written will take into account any required operation that hasn't been computed, and compute it\n",
    "    # This will save a bit of thinking and button pressing. \n",
    "    def __init__(self,data,classes):\n",
    "        \n",
    "        #Time Series Array\n",
    "        self.data=data\n",
    "        #Time Series Classes (if classified, otherwise just pass None)\n",
    "        self.classes=classes\n",
    "        #Dimensions of Time Series Array\n",
    "        self.size=self.data.shape\n",
    "        \n",
    "        #Raw FFT of Each Time Series\n",
    "        self.fft=np.array([])\n",
    "        \n",
    "        #Mean Value of Each Time Series\n",
    "        self.mean=np.array([])\n",
    "        \n",
    "        #The linear term in a linear regression on each time series (i.e. scaled gain)\n",
    "        self.slope=np.array([])\n",
    "        \n",
    "        #The intercepts from linreg on each time series\n",
    "        self.intercept=np.array([])      \n",
    "        \n",
    "        #The rvalues from linreg on each time series\n",
    "        self.rvalues=np.array([])        \n",
    "        \n",
    "        #The pval from linreg on each time series\n",
    "        self.pvalues=np.array([])        \n",
    "        \n",
    "        #The stderr from linreg on each time series\n",
    "        self.stderrors=np.array([])\n",
    "        \n",
    "        #Time Series array with linear trends removed, and \"uniformly\" scaled (divide by the mean value)\n",
    "        self.detrend=np.array([])\n",
    "        \n",
    "        #FFT of windowed detrended time series\n",
    "        self.adjusted_fft_windowed=np.array([])\n",
    "        \n",
    "        \n",
    "        self.max=np.array([])\n",
    "        self.min=np.array([])\n",
    "        \n",
    "        #Laplace Transform of Data\n",
    "        self.laplace=np.array([])\n",
    "        \n",
    "        #Storage for a Continuous Wavelet Transform:\n",
    "        self.cwt=np.array([])\n",
    "\n",
    "        \n",
    "        # PCA on FFT or adjusted FFT (try to get the transpose/not transpose correct)\n",
    "        self.fft_pca=np.array([])\n",
    "        self.adj_fft_pca=np.array([])\n",
    "        \n",
    "        #Arc Length Histogram\n",
    "        self.arc_hist=np.array([])\n",
    "        \n",
    "        \n",
    "        #ElasticNetCV regression coefficients (or whatever other poly reg I like best...)\n",
    "        self.elastic_net=[]            \n",
    "        \n",
    "        #PCA on Raw Data\n",
    "        self.pca=np.array([])\n",
    "        \n",
    "    # FUNCTIONS:    \n",
    "        \n",
    "    #Return FFT of Each Time Series (Calculate if Needed)\n",
    "    def get_fft(self):\n",
    "        if self.fft.size == 0:\n",
    "            self.fft=fft(self.data)\n",
    "        return self.fft\n",
    "        \n",
    "        \n",
    "    #Return Mean Value of Each Time Series\n",
    "    def get_mean(self):\n",
    "        if self.mean.size == 0:\n",
    "            self.mean=np.mean(self.data,axis=0)\n",
    "        return self.mean\n",
    "\n",
    "        #Returns the linear term in a linear regression on each time series (i.e. scaled gain)\n",
    "    def get_slope(self):\n",
    "        if self.slope.size == 0:\n",
    "            intercepts=np.zeros(self.size[1])\n",
    "            slopes=np.zeros(self.size[1])\n",
    "            rvals=np.zeros(self.size[1])\n",
    "            pvals=np.zeros(self.size[1])\n",
    "            stderrs=np.zeros(self.size[1])\n",
    "            for idx, col in zip(range(self.size[1]),self.data.T):\n",
    "                s,i,r,p,st=linregress(range(self.size[0]),col)\n",
    "                intercepts[idx]=i\n",
    "                slopes[idx]=s\n",
    "                rvals[idx]=r\n",
    "                pvals[idx]=p\n",
    "                stderrs[idx]=st\n",
    "            self.intercept=intercepts\n",
    "            self.slope=slopes\n",
    "            self.rvalues=rvals\n",
    "            self.pvalues=pvals\n",
    "            self.stderrors=stderrs\n",
    "        return self.slope\n",
    "        \n",
    "        #Returns the intercepts from linreg on each time series\n",
    "    def get_intercept(self):\n",
    "        if self.intercept.size == 0:\n",
    "            intercepts=np.zeros(self.size[1])\n",
    "            slopes=np.zeros(self.size[1])\n",
    "            rvals=np.zeros(self.size[1])\n",
    "            pvals=np.zeros(self.size[1])\n",
    "            stderrs=np.zeros(self.size[1])\n",
    "            for idx, col in zip(range(self.size[1]),self.data.T):\n",
    "                s,i,r,p,st=linregress(range(self.size[0]),col)\n",
    "                intercepts[idx]=i\n",
    "                slopes[idx]=s\n",
    "                rvals[idx]=r\n",
    "                pvals[idx]=p\n",
    "                stderrs[idx]=st\n",
    "            self.intercept=intercepts\n",
    "            self.slope=slopes\n",
    "            self.rvalues=rvals\n",
    "            self.pvalues=pvals\n",
    "            self.stderrors=stderrs\n",
    "        return self.intercept\n",
    "        \n",
    "        #Time Series array with linear trends removed, and \"uniformly\" scaled (divide by the mean value)\n",
    "    def get_detrend(self):\n",
    "        if self.detrend.size==0:\n",
    "            linout=self.data-np.repeat(np.arange(self.size[0]).T,self.size[1]).reshape(self.size)\\\n",
    "            *self.get_slope().T-np.repeat(self.get_intercept(),self.size[0]).reshape([self.size[1],self.size[0]]).T\n",
    "            self.detrend=np.divide(linout,self.get_mean())\n",
    "        return self.detrend\n",
    "                          \n",
    "                                  \n",
    "        #FFT of windowed detrended time series\n",
    "    def get_adjusted_fft_windowed(self):\n",
    "        if self.adjusted_fft_windowed.size==0:\n",
    "            self.adjusted_fft_windowed=fft((self.get_detrend().T*blackman(self.size[0])).T)\n",
    "        return self.adjusted_fft_windowed\n",
    "\n",
    "    def get_max(self):\n",
    "        if self.max.size==0:\n",
    "            self.max=np.amax(self.data,axis=0)\n",
    "        return self.max\n",
    "    \n",
    "    def get_min(self):\n",
    "        if self.min.size==0:\n",
    "            self.min=np.amin(self.data,axis=0)\n",
    "        return self.min\n",
    "\n",
    "        \n",
    "        #Laplace Transform of Data\n",
    "    def get_laplace(self):\n",
    "        if self.laplace.size==0:\n",
    "            \n",
    "            self.laplace=np.amin(self.data,axis=0)\n",
    "        return self.min        \n",
    "        #Storage for a Continuous Wavelet Transform:\n",
    "        self.cwt1=[]\n",
    "\n",
    "        # PCA on FFT or adjusted FFT (try to get the transpose/not transpose correct)\n",
    "        self.fft_pca=[]\n",
    "        self.adj_fft_pca=[]\n",
    "        \n",
    "        #Arc Length Histogram\n",
    "        self.arc_hist=[]\n",
    "        \n",
    "        \n",
    "        #ElasticNetCV regression coefficients (or whatever other poly reg I like best...)\n",
    "    def get_elastic_net:\n",
    "        if self.elastic_net.size==0:\n",
    "            \n",
    "            el=ElasticNetCV()\n",
    "            el.fit()\n",
    "            for idx, col in zip(range(self.size[1]),self.data.T):\n",
    "                el.fit(range(self.size[0]),col)\n",
    "                \n",
    "            self.elastic_net=np.amin(self.data,axis=0)\n",
    "        return self.min  \n",
    "        \n",
    "        \n",
    "        #PCA on Raw Data\n",
    "        self.pca=[]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "\n",
    "        # - - - - - - To Do: - - - - - - \n",
    "        #    \n",
    "        #    Preprocessing\n",
    "        #    \n",
    "        #    \n",
    "        #    \n",
    "        #    Supervised\n",
    "        #    \n",
    "        #    \n",
    "        #    Unsupervised\n",
    "        #    \n",
    "        #    \n",
    "        #    \n",
    "        #    Plots\n",
    "        #    \n",
    "        #    Comments\n",
    "        #  \n",
    "        #    Pep8\n",
    "        #  \n",
    "        #    Try TSNE instead of PCA\n",
    "        #  \n",
    "        #    Import Dynamic Time Warp Method from Riverside\n",
    "        #    \n",
    "        #    Try Using other Clustering Methods\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Examine:\n",
    "\n",
    "    Mixed Dimension PCA\n",
    "    \n",
    "    Explained Variance from PCA\n",
    "\n",
    "    Make an Analogous \"Which method works best\" to run similar to the UCR program. (And try loads of them)\n",
    "\n",
    "    Test things with Time-It.\n",
    "\n",
    "    Laplace Analysis \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestClass=TimeSeriesClassifier(test_data,test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109,)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestClass.get_min().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431, 109)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestClass.get_adjusted_fft_windowed().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'alpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-323-40b2d77cd516>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbanana\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mElasticNetCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'alpha'"
     ]
    }
   ],
   "source": [
    "banana=ElasticNetCV(alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True,\n",
       "       l1_ratio=0.5, max_iter=1000, n_alphas=100, n_jobs=1,\n",
       "       normalize=False, positive=False, precompute='auto',\n",
       "       random_state=None, selection='cyclic', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana.fit(np.arange(TestClass.size[0]).reshape(-1,1),TestClass.data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.96351879e-20])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
